# Репозиторий лабораторных работ по параллельному программированию

Данный репозиторий содержит лабораторные работы по параллельному программированию с использованием Message Passing Interface (MPI).

## Содержание
1. [Теория](##теория)
2. [Лабораторные работы](##лабораторные-работы)
3. [Установка](##установка)
4. [Использование](##использование)
5. [Полезные материалы](##полезные материалы)

## Теория

### Что такое MPI?

**Message Passing Interface (MPI)** - это стандартизированный и portable интерфейс для передачи сообщений между процессами в распределённых системах. Он позволяет нескольким процессам, работающим на разных процессорах, обмениваться данными и синхронизироваться через передачу сообщений.

#### Основные понятия:
- **Процессы**: Независимые потоки выполнения, работающие одновременно.
- **Коммуникаторы**: Объекты, определяющие группы процессов и позволяющие им общаться (например, `MPI_COMM_WORLD`).
- **Сообщения**: Данные, передаваемые между процессами с атрибутами: отправитель, получатель, тег, коммуникатор.
- **Блокирующая vs Неблокирующая коммуникация**: Блокирующие операции ждут завершения передачи данных, прежде чем продолжить выполнение, неблокирующие операции позволяют процессам продолжать работу.

#### Типы операций:
- **Точка-точка**: Одиночные операции между двумя процессами.
  - Блокирующие: `MPI_Send`, `MPI_Recv`
  - Неблокирующие: `MPI_Isend`, `MPI_Irecv`
- **Коллективные операции**: Операции, включающие все процессы в коммуникаторе.
  - Примеры: `MPI_Bcast`, `MPI_Gather`, `MPI_Allreduce`

#### Архитектура MPI

*Модели программирования*  

- **SPMD (Single Program Multiple Data)** : Все процессы выполняют один и тот же код, но работают с разными данными.
- **MIMD (Multiple Instruction Multiple Data)** : Каждый процесс выполняет свой уникальный код.

*Схема работы*  

- **Инициализация** : Все процессы инициализируют среду MPI и получают свой ранг (`MPI_Comm_rank`) и общее количество процессов (`MPI_Comm_size`).
- **Коммуникация** : Процессы обмениваются данными через коммуникаторы, используя точки-точку или коллективные операции.
- **Завершение** : Все процессы завершают работу MPI через `MPI_Finalize`.

*Схема работы с сообщениями*  

- Процесс отправляет сообщение через `MPI_Send` или `MPI_Isend`.
- Получатель ждёт сообщение через `MPI_Recv` или `MPI_Irecv`.
- Сообщения могут быть синхронизированы (`MPI_Ssend`) или буферизированы (`MPI_Bsend`).

*Коллективные операции*  

- Коллективные операции позволяют эффективно объединить данные из всех процессов:
  - `MPI_Bcast`: Отправка данных от одного процесса всем остальным.
  - `MPI_Gather`: Сбор данных из всех процессов в один.
  - `MPI_Allreduce`: Комбинирование данных всех процессов (например, суммирование, максимум).

*Время и производительность*  

- `MPI_Wtime`: Возвращает астрономическое время в секундах.
- `MPI_Wtick`: Возвращает разрешение таймера в секундах.

#### Важные процедуры:

- `MPI_Init`: Инициализирует среду MPI.
- `MPI_Finalize`: Завершает работу MPI.
- `MPI_Comm_size`: Возвращает количество процессов в коммуникаторе.
- `MPI_Comm_rank`: Возвращает ранг текущего процесса.
- `MPI_Send`/`MPI_Recv`: Блокирующая точка-точка коммуникация.
- `MPI_Isend`/`MPI_Irecv`: Неблокирующая точка-точка коммуникация.
- `MPI_Bcast`: Раздача данных от одного процесса всем остальным.
- `MPI_Reduce`: Комбинирует данные всех процессов

#### Таблица с процедурами:

| **Процедура/Константа/Структура** | **Назначение**                                               |
| --------------------------------- | ------------------------------------------------------------ |
| MPI_Send                          | Отправка сообщения                                           |
| MPI_Recv                          | Прием сообщения                                              |
| MPI_Status                        | Структура статуса сообщения                                  |
| MPI_ANY_SOURCE                    | Константа "Любому процессу"                                  |
| MPI_ANY_TAG                       | Константа "Любой тег сообщения"                              |
| MPI_Get_count                     | Получить количество данных по статусу                        |
| MPI_Get_elements                  | Получить количество базовых элементов по статусу             |
| MPI_Probe                         | Получить данные о сообщении без его приема                   |
| MPI_PROC_NULL                     | Константа-идентификатор не существующего процесса            |
| MPI_Ssend                         | Отправка сообщения которая осуществляет синхронизацию процессов |
| MPI_Bsend                         | Отправка сообщения которая осуществляет буферизацию          |
| MPI_Rsend                         | Отправка сообщения по готовности. Требует инициализации приема у процесса-получателя. |

### Дополнительная информация
- **Буферизация**: `MPI_Bsend` хранит сообщения во внутреннем буфере.
- **Синхронная коммуникация**: `MPI_Ssend` гарантирует синхронизацию процессов.
- **Готовая коммуникация**: `MPI_Rsend` предполагает, что получатель готов принять сообщение.

## Лабораторные работы

В каждом лабораторном занятии рассматриваются различные аспекты программирования на MPI. Тестовые задания одинаковые для всех. Контрольные задания, у каждого индивидуальные.

### Тестовые задания

1. Основы MPI и инициализация процессов.
2. Точка-точка коммуникация.
3. Коллективные операции.

### Контрольная №1

1. Неблокирующая коммуниканикация и её преимущества, измерение эффективности.

### Контрольная №2

1. В каждом процессе дан массив из 5 целых чисел. Используя функцию MPI_Gather,
переслать эти наборы на 2-й процесс и вывести их в порядке возрастания рангов
переславших их процессов (первым вывести набор чисел, данный в главном процессе).

### Контрольная №3

1. 

## Установка

Чтобы настроить среду для работы с MPI, запустить скрипт установки.

## Использование

В каждой лабораторной работе, присутствует Makefile для сборки и запуска бинарного файла.

## Полезные материалы

https://habr.com/ru/articles/121235/

https://habr.com/ru/articles/548266/

https://github.com/open-mpi/ompi

http://www.ccas.ru/mmes/educat/lab04/02/p2pCommI.html#Sec3.3